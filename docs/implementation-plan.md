# Implementation Plan: IP Optimization & Multi-Region Scaling
## Dennis Juma's EKS Infrastructure Enhancement

### Current Status: ‚úÖ **Step 1.1 COMPLETED**
- AWS VPC CNI updated with prefix delegation enabled cluster-wide
- CNI pods restarted and verified

---

## üöÄ **Phase 1: Enable IP Prefix Delegation (Current Cluster)**

### Step 1.1: ‚úÖ **COMPLETED** - Update AWS VPC CNI (Cluster-wide)
```bash
# ‚úÖ DONE - Check current CNI version
kubectl describe daemonset aws-node -n kube-system

# ‚úÖ DONE - Enable prefix delegation cluster-wide
kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION=true
kubectl set env daemonset aws-node -n kube-system WARM_PREFIX_TARGET=1
kubectl rollout restart daemonset aws-node -n kube-system

# ‚úÖ DONE - Verify the change
kubectl get pods -n kube-system -l k8s-app=aws-node
```

### Step 1.2: üéØ **NEXT** - Test with One Tenant (Ezra)

#### Current Configuration to Update:
Located in: `/home/dennis.juma/terraform/regions/us-east-1/layers/01-foundation/production/terraform.tfvars` 

**BEFORE (Current):**
```hcl
client_nodegroups = {
  ezra = {
    capacity_type = "ON_DEMAND"
    instance_types = ["m5.large", "m5a.large", "t3.xlarge", "c5.large"]
    desired_size = 2
    max_size = 4
    min_size = 1
    max_unavailable_percentage = 25
    tier = "general"
    workload = "application"
    performance = "standard"
    enable_client_isolation = true
    custom_taints = []
    extra_labels = {
      client_namespace = "ezra-client-a"
    }
    extra_tags = {
      Owner = "ezra-team"
    }
  }
  
  mtn_ghana = {
    # ... existing config
  }
}
```

**AFTER (Enhanced):**
```hcl
client_nodegroups = {
  ezra = {
    # Existing configuration (unchanged)
    capacity_type = "ON_DEMAND"
    instance_types = ["m5.large", "m5a.large", "t3.xlarge", "c5.large"]
    desired_size = 2
    max_size = 4
    min_size = 1
    max_unavailable_percentage = 25
    tier = "general"
    workload = "application"
    performance = "standard"
    enable_client_isolation = true
    custom_taints = []
    extra_labels = {
      client_namespace = "ezra-client-a"
    }
    extra_tags = {
      Owner = "ezra-team"
    }
    
    # üÜï NEW: IP Optimization Features
    enable_prefix_delegation = true
    max_pods_per_node = 110      # Up from ~29 pods per node
    use_launch_template = true
    disk_size = 20
    bootstrap_extra_args = ""
    dedicated_subnet_ids = []    # Will use existing subnets for now
  }
  
  # Keep MTN Ghana unchanged for now (gradual rollout)
  mtn_ghana = {
    # ... keep existing configuration exactly as-is
    # Add these defaults to maintain compatibility:
    enable_prefix_delegation = false  
    max_pods_per_node = 17           
    use_launch_template = false
    disk_size = 20
    bootstrap_extra_args = ""
    dedicated_subnet_ids = []
  }
}
```

### Step 1.3: üéØ **Deploy Enhanced Configuration**

#### Pre-deployment Validation:
```bash
# Navigate to the foundation layer
cd /home/dennis.juma/terraform/regions/us-east-1/layers/01-foundation/production

# Check current Terraform state
terraform state list | grep nodegroup

# Verify current nodegroup status
aws eks describe-nodegroup --cluster-name us-test-cluster-01 --nodegroup-name ezra-nodegroup --region us-east-1 --query 'nodegroup.status'
```

#### Deployment Commands:
```bash
# 1. Plan the changes (review carefully)
terraform plan -out=prefix-delegation.plan

# 2. Review what will be changed
terraform show prefix-delegation.plan

# 3. Apply the enhancement (this will create new launch template)
terraform apply prefix-delegation.plan
```

#### Expected Changes in Plan:
- ‚úÖ Create new launch template for Ezra nodegroup
- ‚úÖ Update nodegroup configuration to use launch template
- ‚ö†Ô∏è Nodegroup will perform rolling update (gradual node replacement)
- üîí MTN Ghana nodegroup unchanged

### Step 1.4: üéØ **Validate Prefix Delegation**

#### Check Node Configuration:
```bash
# List all nodes and their max pod capacity
kubectl get nodes -o custom-columns="NAME:.metadata.name,PODS:.status.capacity.pods,INSTANCE:.metadata.labels.node\.kubernetes\.io/instance-type"

# Verify specific Ezra nodes have higher pod capacity
kubectl get nodes -l client=ezra -o custom-columns="NAME:.metadata.name,PODS:.status.capacity.pods"

# Should show ~110 pods per node instead of ~29
```

#### Monitor IP Allocation:
```bash
# Check current pod distribution
kubectl get pods -n ezra-client-a -o wide | head -10

# Monitor AWS VPC CNI logs during scaling
kubectl logs -n kube-system -l k8s-app=aws-node --tail=20

# Check ENI allocation on nodes
kubectl describe node <ezra-node-name> | grep -A 10 "Addresses"
```

#### Validate Performance:
```bash
# Scale up Ezra workload to test higher pod density
kubectl get deployments -n ezra-client-a

# Check resource utilization
kubectl top nodes -l client=ezra
kubectl top pods -n ezra-client-a
```

---

## üìã **Rollback Plan (If Issues Occur)**

### Emergency Rollback Steps:
```bash
# 1. Disable new features in terraform.tfvars
enable_prefix_delegation = false
use_launch_template = false

# 2. Apply rollback configuration
terraform apply -auto-approve

# 3. If CNI issues, rollback CNI settings
kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION-
kubectl rollout restart daemonset aws-node -n kube-system
```

---

## üìä **Expected Results After Step 1.2**

### IP Capacity Improvement:
```
BEFORE:
- Ezra nodes: ~29 pods max per node
- 2 nodes = ~58 total pods capacity

AFTER:  
- Ezra nodes: ~110 pods max per node
- 2 nodes = ~220 total pods capacity
- üöÄ 280% improvement in pod density!
```

### Monitoring Metrics to Track:
1. **Pod Density**: Pods per node should increase from ~29 to ~110
2. **IP Utilization**: Subnet IP usage should be more efficient  
3. **Node Scaling**: Fewer nodes needed for same workload
4. **Performance**: No degradation in application response times
5. **Cost**: Potential cost savings from better resource utilization

---

## üéØ **Next Phase Preview (After 1.2 Success)**

### Phase 2: Add MTN Ghana to Enhanced Setup
- Apply same configuration to MTN Ghana nodegroup
- Validate isolation between tenants still works
- Monitor both tenants with enhanced IP allocation

### Phase 3: Dedicated Tenant Subnets (Optional)
- Create subnet module for deeper isolation
- Migrate tenants to dedicated subnets
- Implement network-level isolation

### Phase 4: Multi-Region Expansion
- Replicate enhanced setup in us-west-2
- Independent regional clusters
- Same codebase, different regions

---

## üõü **Support Commands**

### Debugging Commands:
```bash
# Check CNI configuration
kubectl get configmap amazon-vpc-cni -n kube-system -o yaml

# View CNI plugin logs
kubectl logs -n kube-system -l k8s-app=aws-node -c aws-vpc-cni-init

# Check ENI allocation
aws ec2 describe-network-interfaces --filters "Name=status,Values=in-use" --query 'NetworkInterfaces[?contains(Description, `us-test-cluster-01`)].[NetworkInterfaceId,PrivateIpAddress,Status]' --output table --region us-east-1
```

### Health Checks:
```bash
# Verify cluster health
kubectl get nodes -o wide
kubectl get pods --all-namespaces | grep -E "(Pending|Error|CrashLoop)"

# Check autoscaler status  
kubectl logs -n kube-system -l app=cluster-autoscaler --tail=10
```

---

**STATUS: Ready for Step 1.2 implementation**
**NEXT ACTION: Update terraform.tfvars with enhanced Ezra configuration**
